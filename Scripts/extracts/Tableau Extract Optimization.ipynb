{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook describes a method for optimizing extract operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Priority Equation\n",
    "\n",
    "\\begin{equation*}\n",
    "Rank(\\overline{C}\\left({completion - start }\\right) * \\left(\\frac{\\left( \\sum_{k=1}^n failed \\right)}{\\left( \\sum_{k=1}^n completed \\right)}+1\\right))-1 * ((max_p - min_p)/(size-1)) + min_p\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import your packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pprint\n",
    "import datetime as dt\n",
    "import binascii\n",
    "import json\n",
    "import Crypto\n",
    "from Crypto.PublicKey import RSA\n",
    "from Crypto.Cipher import PKCS1_v1_5\n",
    "from Crypto.Cipher import PKCS1_v1_5\n",
    "from base64 import b64decode\n",
    "import requests\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we set our connection information\n",
    "We also set the minimum priority, 5 in this case, so that we can save space for High Priority tasks driven by the business, not performance.\n",
    "We then set our maximum priority, 75 in this case, so that there is room for subscriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url_from = 'https://'\n",
    "tab_server_url = 'tableau.zillow.local'\n",
    "full_url = url_from+tab_server_url\n",
    "tableau_username = ''\n",
    "tableau_password = '\\'\n",
    "postgres_user = ''\n",
    "postgres_pwd = ''\n",
    "postgres_db = 'workgroup'\n",
    "postgres_port = 8060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add our priority information (min, max) here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_priority = 5\n",
    "max_priority = 75\n",
    "delta = max_priority - min_priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we connect to our Postgres repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn_string = \"host='%s' dbname='%s' user='%s' password='%s' port='%s'\" % (tab_server_url,postgres_db,postgres_user,postgres_pwd,postgres_port)\n",
    "conn = psycopg2.connect(conn_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we are connected, let's get our background_tasks into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"select a.id, a.job_name, a.started_at, a.completed_at, a.finish_code, a.site_id, c.schedule_id, a.correlation_id, b.name from background_jobs a join sites b on a.site_id = b.id join tasks c on a.correlation_id = c.id where a.job_type like '%extract%'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_sql(query, con=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute completion time\n",
    "\n",
    "\\begin{equation*}\n",
    "Duration   = {completion time - start time}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff']=df['completed_at']-df['started_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the data to seconds, using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff']=df['diff'] / np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation is up next. \n",
    "Group by site, schedule and the correlation id.\n",
    "\n",
    "*What is correlation id?*\n",
    "\n",
    "Correlation ID is the Postgres identifier for the task (in this case the workbook refresh). It can also be a data source refresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby(['site_id','schedule_id','correlation_id']).agg({'correlation_id':'size','finish_code':sum, 'diff':'mean'})\n",
    "df_agg.rename(columns={'correlation_id':'count_rows'}, inplace=True)\n",
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says group by site, schedule and task, and then aggregates each column independently.\n",
    "1. Size: how many records do we have\n",
    "2. Finish_code: 1 = failure, so sum will be how many failures we have had\n",
    "3. Diff: average time to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the completion rate for each job\n",
    "\\begin{equation*}\n",
    "Completion Rate   = \\left( \\sum_{k=1}^n failed \\right)/\\left( \\sum_{k=1}^n completed \\right)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_agg['completion'] = (df_agg['finish_code']/df_agg['count_rows'])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the penalty for failed jobs\n",
    "\\begin{equation*}\n",
    "Penalty   = {duration * completion}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_agg['penalty'] = df_agg['diff']*df_agg['completion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank penalty within each Site and Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_agg['rank'] = df_agg.groupby(['site_id','schedule_id'])['penalty'].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_len = df_agg.groupby(['site_id','schedule_id']).size()\n",
    "df_len = pd.DataFrame(df_len, columns=['group_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_len.reset_index(inplace=True)\n",
    "df_len.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_agg.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = df_agg.merge(df_len, on=['site_id','schedule_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Priority\n",
    "\\begin{equation*}\n",
    "Priority   = {(rank-1) * ((maxpriority-minpriority)/(groupsize-1)) +minpriority}\n",
    "\\end{equation*}\n",
    "\n",
    "*This needs to be an integer for Tableau Server*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['rank_1'] = (df_full['rank']-1)\n",
    "df_full['steps'] = np.where(df_full['group_size'] == 1, 1, delta/(df_full['group_size']-1))\n",
    "df_full['min'] = min_priority\n",
    "df_full['priority'] = (df_full['steps']*df_full['rank_1']+min_priority).astype(int)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop off everything but correlation_id and priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['correlation_id','priority']\n",
    "df_full = df_full[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full.set_index('correlation_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a dictionary to iterate over for calling VizPortalAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "priority = []\n",
    "for index, row in df_full.iterrows():\n",
    "    priority.append({'id':index, 'priority':row['priority']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tableau Setup Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_for_display(text):\n",
    "    \"\"\"\n",
    "    Encodes strings so they can display as ASCII in a Windows terminal window.\n",
    "    This function also encodes strings for processing by xml.etree.ElementTree functions.\n",
    "    Returns an ASCII-encoded version of the text.\n",
    "    Unicode characters are converted to ASCII placeholders (for example, \"?\").\n",
    "    \"\"\"\n",
    "    return text.encode('ascii', errors=\"backslashreplace\").decode('utf-8')\n",
    "\n",
    "# Establish a session so we can retain the cookies\n",
    "session = requests.Session()\n",
    "\n",
    "def generatePublicKey():\n",
    "      payload = \"{\\\"method\\\":\\\"generatePublicKey\\\",\\\"params\\\":{}}\"\n",
    "      endpoint = \"generatePublicKey\"\n",
    "      url = full_url + \"/vizportal/api/web/v1/\"+endpoint\n",
    "      headers = {\n",
    "      'content-type': \"application/json;charset=UTF-8\",\n",
    "      'accept': \"application/json, text/plain, */*\",\n",
    "      'cache-control': \"no-cache\"\n",
    "      }\n",
    "      response = session.post(url, data=payload, headers=headers, verify=False)\n",
    "      response_text = json.loads(_encode_for_display(response.text))\n",
    "      response_values = {\"keyId\":response_text[\"result\"][\"keyId\"], \"n\":response_text[\"result\"][\"key\"][\"n\"],\"e\":response_text[\"result\"][\"key\"][\"e\"]}\n",
    "      return response_values\n",
    "\n",
    "# Generate a pubilc key that will be used to encrypt the user's password\n",
    "public_key = generatePublicKey()\n",
    "pk = public_key[\"keyId\"]\n",
    "\n",
    "\n",
    "# Encrypt with RSA public key (it's important to use PKCS11)\n",
    "def assymmetric_encrypt(val, public_key):\n",
    "     modulusDecoded = long(public_key[\"n\"], 16)\n",
    "     exponentDecoded = long(public_key[\"e\"], 16)\n",
    "     keyPub = RSA.construct((modulusDecoded, exponentDecoded))\n",
    "     # Generate a cypher using the PKCS1.5 standard\n",
    "     cipher = PKCS1_v1_5.new(keyPub)\n",
    "     return cipher.encrypt(val)\n",
    "\n",
    "# Encrypt the password used to login\n",
    "encryptedPassword = assymmetric_encrypt(tableau_password,public_key)\n",
    "\n",
    "def vizportalLogin(encryptedPassword, keyId):\n",
    "     encodedPassword = binascii.b2a_hex(encryptedPassword)\n",
    "     payload = \"{\\\"method\\\":\\\"login\\\",\\\"params\\\":{\\\"username\\\":\\\"%s\\\", \\\"encryptedPassword\\\":\\\"%s\\\", \\\"keyId\\\":\\\"%s\\\"}}\" % (tableau_username, encodedPassword,keyId)\n",
    "     endpoint = \"login\"\n",
    "     url = full_url + \"/vizportal/api/web/v1/\"+endpoint\n",
    "     headers = {\n",
    "     'content-type': \"application/json;charset=UTF-8\",\n",
    "     'accept': \"application/json, text/plain, */*\",\n",
    "     'cache-control': \"no-cache\"\n",
    "     }\n",
    "     response = session.post(url, data=payload, headers=headers,verify=False)\n",
    "     return response\n",
    "\n",
    "login_response = vizportalLogin(encryptedPassword, pk)\n",
    "if login_response.status_code == 200:\n",
    "    print \"Login to Vizportal Successful!\"\n",
    "\n",
    "sc = login_response.headers[\"Set-Cookie\"]\n",
    "headers = []\n",
    "for item in sc.split(\";\"):\n",
    "    if \"workgroup\" in item:\n",
    "        headers.append(item.split(\"=\")[1])\n",
    "    elif \"XSRF\" in item:\n",
    "        headers.append(item.split(\"=\")[1])\n",
    "workgroup_session_id, xsrf_token = headers[0], headers[1]\n",
    "\n",
    "def setPriority(task,priority):\n",
    "    payload = \"{  \\\"method\\\": \\\"setExtractTasksPriority\\\",\\\"params\\\": {\\\"ids\\\": [\\\"%s\\\"],\\\"priority\\\": \\\"%s\\\"}}\" % (task,priority)\n",
    "    endpoint = \"setExtractTasksPriority\"\n",
    "    url = full_url + \"/vizportal/api/web/v1/\"+endpoint\n",
    "    headers = {\n",
    "    'content-type': \"application/json;charset=UTF-8\",\n",
    "    'accept': \"application/json, text/plain, */*\",\n",
    "    'cache-control': \"no-cache\",\n",
    "    'x-xsrf-token': xsrf_token,\n",
    "    'cookie': \"workgroup_session_id=\"+workgroup_session_id+\"; XSRF-TOKEN=\"+xsrf_token\n",
    "    }\n",
    "    response = session.post(url, data=payload, headers=headers,verify=False) \n",
    "    print response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(priority)):\n",
    "    print str(priority[i]['id'])+' '+str(priority[i]['priority'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setPriority('6464',100)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
